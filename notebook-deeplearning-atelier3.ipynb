{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-15T20:20:46.695772Z",
     "iopub.status.busy": "2025-12-15T20:20:46.695070Z",
     "iopub.status.idle": "2025-12-15T20:21:06.335000Z",
     "shell.execute_reply": "2025-12-15T20:21:06.334063Z",
     "shell.execute_reply.started": "2025-12-15T20:20:46.695740Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch)\n",
      "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m  \u001b[33m0:00:18\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m  \u001b[33m0:00:13\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.1-py3-none-any.whl (16 kB)\n",
      "Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/25\u001b[0m [torchvision]\u001b[0m [torchvision]ver-cu12]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.20.1 fsspec-2025.12.0 mpmath-1.3.0 networkx-3.6.1 numpy-2.3.5 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pillow-12.0.0 sympy-1.14.0 torch-2.9.1 torchvision-0.24.1 triton-3.5.1\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (3.20.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: pytz, xxhash, tqdm, safetensors, regex, pyarrow, propcache, multidict, hf-xet, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspecm╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/22\u001b[0m [hf-xet]]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.12.0━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/22\u001b[0m [hf-xet]\n",
      "\u001b[2K    Uninstalling fsspec-2025.12.0:90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/22\u001b[0m [hf-xet]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.12.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/22\u001b[0m [hf-xet]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/22\u001b[0m [datasets]/22\u001b[0m [datasets]ers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 datasets-4.4.1 dill-0.4.0 frozenlist-1.8.0 fsspec-2025.10.0 hf-xet-1.2.0 huggingface-hub-0.36.0 multidict-6.7.0 multiprocess-0.70.18 pandas-2.3.3 propcache-0.4.1 pyarrow-22.0.0 pytz-2025.2 regex-2025.11.3 safetensors-0.7.0 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.57.3 xxhash-3.6.0 yarl-1.22.0\n",
      "Requirement already satisfied: pandas in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.3.5)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [openpyxl]1/2\u001b[0m [openpyxl]\n",
      "\u001b[1A\u001b[2KSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Requirement already satisfied: beautifulsoup4 in /home/codespace/.local/lib/python3.12/site-packages (4.14.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2025.11.12)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy>=1.24.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from scikit-learn) (2.3.5)\n",
      "Collecting scipy>=1.10.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, pyparsing, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, matplotlib, seaborn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [seaborn]0/11\u001b[0m [seaborn]ib]n]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 joblib-1.5.3 kiwisolver-1.4.9 matplotlib-3.10.8 pyparsing-3.2.5 scikit-learn-1.8.0 scipy-1.16.3 seaborn-0.13.2 threadpoolctl-3.6.0\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting camel-tools\n",
      "  Downloading camel_tools-1.5.7-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: joblib in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Collecting future (from camel-tools)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.12/site-packages (from camel-tools) (1.17.0)\n",
      "Collecting docopt (from camel-tools)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cachetools<=6.0.0 (from camel-tools)\n",
      "  Downloading cachetools-6.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting numpy<2 (from camel-tools)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/python/3.12.1/lib/python3.12/site-packages (from camel-tools) (1.16.3)\n",
      "Requirement already satisfied: pandas in /usr/local/python/3.12.1/lib/python3.12/site-packages (from camel-tools) (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/python/3.12.1/lib/python3.12/site-packages (from camel-tools) (1.8.0)\n",
      "Requirement already satisfied: dill in /usr/local/python/3.12.1/lib/python3.12/site-packages (from camel-tools) (0.4.0)\n",
      "Requirement already satisfied: torch>=2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from camel-tools) (2.9.1)\n",
      "Collecting transformers<4.44.0,>=4.0 (from camel-tools)\n",
      "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting editdistance (from camel-tools)\n",
      "  Downloading editdistance-0.8.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from camel-tools) (2.32.5)\n",
      "Collecting emoji (from camel-tools)\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting pyrsistent (from camel-tools)\n",
      "  Downloading pyrsistent-0.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting tabulate (from camel-tools)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting muddler (from camel-tools)\n",
      "  Downloading muddler-0.1.3-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting camel-kenlm<=2025.09.16 (from camel-tools)\n",
      "  Downloading camel_kenlm-2025.9.16-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (251 bytes)\n",
      "Requirement already satisfied: filelock in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<4.44.0,>=4.0->camel-tools) (3.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers<4.44.0,>=4.0->camel-tools) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers<4.44.0,>=4.0->camel-tools) (6.0.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.7.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<4.44.0,>=4.0->camel-tools)\n",
      "  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers<4.44.0,>=4.0->camel-tools) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers<4.44.0,>=4.0->camel-tools) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers<4.44.0,>=4.0->camel-tools) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=2.0->camel-tools) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0->camel-tools) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=2.0->camel-tools) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->camel-tools) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pandas->camel-tools) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->camel-tools) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->camel-tools) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->camel-tools) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->camel-tools) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->camel-tools) (2025.11.12)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from scikit-learn->camel-tools) (3.6.0)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading camel_tools-1.5.7-py3-none-any.whl (124 kB)\n",
      "Downloading cachetools-6.0.0-py3-none-any.whl (10 kB)\n",
      "Downloading camel_kenlm-2025.9.16-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading editdistance-0.8.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (418 kB)\n",
      "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading muddler-0.1.3-py3-none-any.whl (16 kB)\n",
      "Downloading pyrsistent-0.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (122 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13783 sha256=8c756fb19271b6dffa12e6427241fe98b310192a9b9e73da572479a34dfe2081\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, camel-kenlm, tabulate, pyrsistent, numpy, muddler, future, emoji, editdistance, click, cachetools, nltk, tokenizers, transformers, camel-tools\n",
      "\u001b[2K  Attempting uninstall: numpym\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [pyrsistent]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.5━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [pyrsistent]\n",
      "\u001b[2K    Uninstalling numpy-2.3.5:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [pyrsistent]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.5━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [pyrsistent]\n",
      "\u001b[2K  Attempting uninstall: tokenizers━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nltk]tools]\n",
      "\u001b[2K    Found existing installation: tokenizers 0.22.10m━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nltk]\n",
      "\u001b[2K    Uninstalling tokenizers-0.22.1:0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nltk]\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.22.1[90m━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nltk]\n",
      "\u001b[2K  Attempting uninstall: transformersm\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nltk]\n",
      "\u001b[2K    Found existing installation: transformers 4.57.3━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nltk]\n",
      "\u001b[2K    Uninstalling transformers-4.57.3:━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m13/15\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.57.3m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m13/15\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [camel-tools]\u001b[0m [camel-tools]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed cachetools-6.0.0 camel-kenlm-2025.9.16 camel-tools-1.5.7 click-8.3.1 docopt-0.6.2 editdistance-0.8.1 emoji-2.15.0 future-1.0.0 muddler-0.1.3 nltk-3.9.2 numpy-1.26.4 pyrsistent-0.20.0 tabulate-0.9.0 tokenizers-0.19.1 transformers-4.43.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PyTorch version: 2.9.1+cu128\n",
      " CUDA disponible: False\n"
     ]
    }
   ],
   "source": [
    "# Installation \n",
    "!pip install torch torchvision\n",
    "!pip install transformers datasets  \n",
    "!pip install pandas numpy openpyxl\n",
    "!pip install beautifulsoup4 requests\n",
    "!pip install scikit-learn matplotlib seaborn\n",
    "!pip install nltk camel-tools\n",
    "\n",
    "# Vérifier l'installation\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import torch\n",
    "print(f\" PyTorch version: {torch.__version__}\")\n",
    "print(f\" CUDA disponible: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T22:50:50.627212Z",
     "iopub.status.busy": "2025-12-15T22:50:50.626364Z",
     "iopub.status.idle": "2025-12-15T22:50:50.631023Z",
     "shell.execute_reply": "2025-12-15T22:50:50.630045Z",
     "shell.execute_reply.started": "2025-12-15T22:50:50.627179Z"
    }
   },
   "source": [
    "# Part1 Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T14:03:28.197294Z",
     "iopub.status.busy": "2025-12-15T14:03:28.197110Z",
     "iopub.status.idle": "2025-12-15T14:03:28.204743Z",
     "shell.execute_reply": "2025-12-15T14:03:28.203804Z",
     "shell.execute_reply.started": "2025-12-15T14:03:28.197277Z"
    }
   },
   "source": [
    "# QUESTION 1: Web Scraping de textes arabes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T22:28:25.072301Z",
     "iopub.status.busy": "2025-12-15T22:28:25.071570Z",
     "iopub.status.idle": "2025-12-15T22:28:25.082799Z",
     "shell.execute_reply": "2025-12-15T22:28:25.082093Z",
     "shell.execute_reply.started": "2025-12-15T22:28:25.072269Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset créé : 16 textes\n",
      "                                                Text  Score\n",
      "0  الذكاء الاصطناعي يغير العالم بشكل جذري ويؤثر ع...    8.5\n",
      "1  تطور التكنولوجيا الحديثة يساعد في تحسين الخدما...    7.0\n",
      "2  الرياضة لها فوائد صحية عديدة وتساعد على تحسين ...    6.5\n",
      "3  التغير المناخي يشكل تهديدا كبيرا للبشرية ويتطل...    9.0\n",
      "4  الاقتصاد الرقمي يوفر فرصا جديدة للشركات الناشئ...    7.5\n",
      "Fichier sauvegardé : arabic_texts_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Création dataset manuel (16 textes, scores 0-10)\n",
    "data = {\n",
    "    'Text': [\n",
    "        \"الذكاء الاصطناعي يغير العالم بشكل جذري ويؤثر على جميع جوانب حياتنا اليومية\",\n",
    "        \"تطور التكنولوجيا الحديثة يساعد في تحسين الخدمات الصحية والتعليمية\",\n",
    "        \"الرياضة لها فوائد صحية عديدة وتساعد على تحسين اللياقة البدنية\",\n",
    "        \"التغير المناخي يشكل تهديدا كبيرا للبشرية ويتطلب إجراءات عاجلة\",\n",
    "        \"الاقتصاد الرقمي يوفر فرصا جديدة للشركات الناشئة والمبدعين\",\n",
    "        \"التعليم عن بعد أصبح ضرورة في العصر الحديث وله مزايا متعددة\",\n",
    "        \"الأمن السيبراني أصبح من أهم التحديات في عالم الإنترنت المعاصر\",\n",
    "        \"الطاقة المتجددة هي المستقبل للحفاظ على البيئة وتقليل الانبعاثات\",\n",
    "        \"الثورة الصناعية الرابعة تعتمد على الأتمتة والذكاء الاصطناعي\",\n",
    "        \"البحث العلمي يساهم في تطوير المجتمعات وحل المشكلات المعقدة\",\n",
    "        \"الإنترنت غير طريقة التواصل بين الناس في جميع أنحاء العالم\",\n",
    "        \"الطب الحديث حقق إنجازات كبيرة في علاج الأمراض المستعصية\",\n",
    "        \"الفن والثقافة يعكسان هوية الشعوب وتاريخها الحضاري\",\n",
    "        \"التجارة الإلكترونية سهلت عملية الشراء والبيع عبر الإنترنت\",\n",
    "        \"الزراعة الذكية تستخدم التكنولوجيا لزيادة الإنتاج وتقليل الهدر\",\n",
    "        \"الفضاء الخارجي يفتح آفاقا جديدة للاستكشاف والبحث العلمي\"\n",
    "    ],\n",
    "    'Score': [8.5, 7.0, 6.5, 9.0, 7.5, 8.0, 8.5, 9.5, 8.0, 7.5, 6.0, 8.5, 5.5, 7.0, 8.0, 9.0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('arabic_texts_dataset.csv', index=False, encoding='utf-8-sig')\n",
    "print(f\"Dataset créé : {len(df)} textes\")\n",
    "print(df.head())\n",
    "print(\"Fichier sauvegardé : arabic_texts_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 2 : Pipeline de Preprocessing NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T22:28:29.277170Z",
     "iopub.status.busy": "2025-12-15T22:28:29.276619Z",
     "iopub.status.idle": "2025-12-15T22:28:32.409100Z",
     "shell.execute_reply": "2025-12-15T22:28:32.408107Z",
     "shell.execute_reply.started": "2025-12-15T22:28:29.277146Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
      "Preprocessing terminé !\n",
      "                                                Text  \\\n",
      "0  الذكاء الاصطناعي يغير العالم بشكل جذري ويؤثر ع...   \n",
      "1  تطور التكنولوجيا الحديثة يساعد في تحسين الخدما...   \n",
      "2  الرياضة لها فوائد صحية عديدة وتساعد على تحسين ...   \n",
      "3  التغير المناخي يشكل تهديدا كبيرا للبشرية ويتطل...   \n",
      "4  الاقتصاد الرقمي يوفر فرصا جديدة للشركات الناشئ...   \n",
      "\n",
      "                                      processed_text  Score  label  \n",
      "0  ذكاء اصطناع يغير عالم شكل جذر يءثر علي جوانب ح...    8.5      3  \n",
      "1     تطور تكنولوجيا حديث يساعد تحس خدم صحي التعليمي    7.0      2  \n",
      "2         رياض واءد صحي عديد تساعد علي تحس لياق بدني    6.5      2  \n",
      "3  تغير مناخ يشكل تهديدا بيرا لبشري يتطلب اجراء عاجل    9.0      3  \n",
      "4          اقتصاد رقم يوفر رصا جديد لشرك ناشء المبدع    7.5      2  \n",
      "\n",
      "Distribution labels: label\n",
      "1    1\n",
      "2    6\n",
      "3    9\n",
      "Name: count, dtype: int64\n",
      "Nombre de stop words utilisés: 701\n",
      "Fichier sauvegardé : arabic_texts_preprocessed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Installation\n",
    "!pip install nltk\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class ArabicPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(nltk.corpus.stopwords.words('arabic'))\n",
    "    \n",
    "    def normalize_arabic(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        text = re.sub(r\"[إأآا]\", \"ا\", text)\n",
    "        text = re.sub(r\"ى\", \"ي\", text)\n",
    "        text = re.sub(r\"ؤ\", \"ء\", text)\n",
    "        text = re.sub(r\"ئ\", \"ء\", text)\n",
    "        text = re.sub(r\"ة\", \"ه\", text)\n",
    "        text = re.sub(r\"([ًٌٍَُِّْ])\", \"\", text)\n",
    "        text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        text = self.normalize_arabic(text)\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        return tokens\n",
    "    \n",
    "    def remove_stopwords(self, tokens):\n",
    "        return [token for token in tokens if token not in self.stop_words and len(token) > 1]\n",
    "    \n",
    "    def stem_arabic(self, word):\n",
    "        prefixes = ['ال', 'و', 'ف', 'ب', 'ك', 'ل']\n",
    "        for prefix in prefixes:\n",
    "            if word.startswith(prefix) and len(word) > len(prefix) + 2:\n",
    "                word = word[len(prefix):]\n",
    "                break\n",
    "        suffixes = ['ها', 'ان', 'ات', 'ون', 'ين', 'ه', 'ك', 'ي', 'ن']\n",
    "        for suffix in suffixes:\n",
    "            if word.endswith(suffix) and len(word) > len(suffix) + 2:\n",
    "                word = word[:-len(suffix)]\n",
    "                break\n",
    "        return word\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        tokens = self.tokenize(text)\n",
    "        tokens = self.remove_stopwords(tokens)\n",
    "        tokens = [self.stem_arabic(token) for token in tokens]\n",
    "        return ' '.join([t for t in tokens if t])\n",
    "    \n",
    "    def discretize_scores(self, scores):\n",
    "        categories = []\n",
    "        for score in scores:\n",
    "            if score < 3:\n",
    "                categories.append('Faible')\n",
    "            elif score < 6:\n",
    "                categories.append('Moyen')\n",
    "            elif score < 8:\n",
    "                categories.append('Bon')\n",
    "            else:\n",
    "                categories.append('Excellent')\n",
    "        return categories\n",
    "\n",
    "# Chargement et préprocessing\n",
    "df = pd.read_csv('arabic_texts_dataset.csv')\n",
    "if len(df) == 0:\n",
    "    print(\"Erreur : Dataset vide ! Exécute 1.1 d'abord.\")\n",
    "else:\n",
    "    preprocessor = ArabicPreprocessor()\n",
    "    df['processed_text'] = df['Text'].apply(preprocessor.preprocess_text)\n",
    "    df['score_category'] = preprocessor.discretize_scores(df['Score'])\n",
    "    category_mapping = {'Faible': 0, 'Moyen': 1, 'Bon': 2, 'Excellent': 3}\n",
    "    df['label'] = df['score_category'].map(category_mapping)\n",
    "    df.to_csv('arabic_texts_preprocessed.csv', index=False, encoding='utf-8-sig')\n",
    "    print(\"Preprocessing terminé !\")\n",
    "    print(df[['Text', 'processed_text', 'Score', 'label']].head())\n",
    "    print(\"\\nDistribution labels:\", df['label'].value_counts().sort_index())\n",
    "    print(f\"Nombre de stop words utilisés: {len(preprocessor.stop_words)}\")\n",
    "    print(\"Fichier sauvegardé : arabic_texts_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-15T19:38:28.660185Z"
    }
   },
   "source": [
    "# QUESTION 3 : Entraînement des Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T22:29:30.130871Z",
     "iopub.status.busy": "2025-12-15T22:29:30.130572Z",
     "iopub.status.idle": "2025-12-15T22:29:45.526910Z",
     "shell.execute_reply": "2025-12-15T22:29:45.526167Z",
     "shell.execute_reply.started": "2025-12-15T22:29:30.130848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\n",
      "\n",
      "Tuning RNN...\n",
      "Epoch 5/20 - Train Loss: 1.0847, Train Acc: 0.4167, Val Loss: 1.0824, Val Acc: 0.7500\n",
      "Epoch 10/20 - Train Loss: 1.0631, Train Acc: 0.6667, Val Loss: 1.0746, Val Acc: 0.7500\n",
      "Epoch 15/20 - Train Loss: 1.0975, Train Acc: 0.4167, Val Loss: 1.0673, Val Acc: 0.7500\n",
      "Epoch 20/20 - Train Loss: 1.0647, Train Acc: 0.5833, Val Loss: 1.0598, Val Acc: 0.7500\n",
      "Epoch 5/20 - Train Loss: 1.0697, Train Acc: 0.4167, Val Loss: 1.1067, Val Acc: 0.2500\n",
      "Epoch 10/20 - Train Loss: 1.0770, Train Acc: 0.4167, Val Loss: 1.0978, Val Acc: 0.2500\n",
      "Epoch 15/20 - Train Loss: 1.0633, Train Acc: 0.4167, Val Loss: 1.0886, Val Acc: 0.2500\n",
      "Epoch 20/20 - Train Loss: 1.0701, Train Acc: 0.4167, Val Loss: 1.0805, Val Acc: 0.2500\n",
      "Epoch 5/20 - Train Loss: 1.0592, Train Acc: 0.2500, Val Loss: 1.0228, Val Acc: 0.2500\n",
      "Epoch 10/20 - Train Loss: 0.9967, Train Acc: 0.5833, Val Loss: 0.9550, Val Acc: 0.7500\n",
      "Epoch 15/20 - Train Loss: 0.9759, Train Acc: 0.5000, Val Loss: 0.8974, Val Acc: 0.7500\n",
      "Epoch 20/20 - Train Loss: 0.9463, Train Acc: 0.5000, Val Loss: 0.8482, Val Acc: 0.7500\n",
      "Epoch 5/20 - Train Loss: 1.0002, Train Acc: 0.4167, Val Loss: 0.9328, Val Acc: 0.7500\n",
      "Epoch 10/20 - Train Loss: 0.9807, Train Acc: 0.5000, Val Loss: 0.8536, Val Acc: 0.7500\n",
      "Epoch 15/20 - Train Loss: 0.9950, Train Acc: 0.4167, Val Loss: 0.8097, Val Acc: 0.7500\n",
      "Epoch 20/20 - Train Loss: 0.9605, Train Acc: 0.5000, Val Loss: 0.7944, Val Acc: 0.7500\n",
      "Meilleurs params pour RNN: {'lr': 0.001, 'hidden_dim': 128}, Acc: 0.7500\n",
      "\n",
      "Tuning BiRNN...\n",
      "Epoch 5/20 - Train Loss: 1.0530, Train Acc: 0.5000, Val Loss: 1.0652, Val Acc: 0.5000\n",
      "Epoch 10/20 - Train Loss: 0.9480, Train Acc: 0.6667, Val Loss: 1.0619, Val Acc: 0.5000\n",
      "Epoch 15/20 - Train Loss: 0.9349, Train Acc: 0.5833, Val Loss: 1.0558, Val Acc: 0.5000\n",
      "Epoch 20/20 - Train Loss: 0.9007, Train Acc: 0.7500, Val Loss: 1.0508, Val Acc: 0.5000\n",
      "Epoch 5/20 - Train Loss: 1.2942, Train Acc: 0.0833, Val Loss: 0.9895, Val Acc: 0.7500\n",
      "Epoch 10/20 - Train Loss: 1.2700, Train Acc: 0.1667, Val Loss: 0.9916, Val Acc: 0.7500\n",
      "Epoch 15/20 - Train Loss: 1.2440, Train Acc: 0.1667, Val Loss: 0.9920, Val Acc: 0.5000\n",
      "Epoch 20/20 - Train Loss: 1.0467, Train Acc: 0.3333, Val Loss: 0.9911, Val Acc: 0.5000\n",
      "Epoch 5/20 - Train Loss: 0.7072, Train Acc: 0.8333, Val Loss: 1.0606, Val Acc: 0.2500\n",
      "Epoch 10/20 - Train Loss: 0.4767, Train Acc: 1.0000, Val Loss: 1.0874, Val Acc: 0.2500\n",
      "Epoch 15/20 - Train Loss: 0.3109, Train Acc: 1.0000, Val Loss: 1.1204, Val Acc: 0.2500\n",
      "Epoch 20/20 - Train Loss: 0.1738, Train Acc: 1.0000, Val Loss: 1.1642, Val Acc: 0.2500\n",
      "Epoch 5/20 - Train Loss: 0.8458, Train Acc: 0.6667, Val Loss: 1.2697, Val Acc: 0.0000\n",
      "Epoch 10/20 - Train Loss: 0.6951, Train Acc: 0.8333, Val Loss: 1.2321, Val Acc: 0.2500\n",
      "Epoch 15/20 - Train Loss: 0.5077, Train Acc: 1.0000, Val Loss: 1.2114, Val Acc: 0.2500\n",
      "Epoch 20/20 - Train Loss: 0.3671, Train Acc: 0.9167, Val Loss: 1.1897, Val Acc: 0.5000\n",
      "Meilleurs params pour BiRNN: {'lr': 0.001, 'hidden_dim': 128}, Acc: 0.5000\n",
      "\n",
      "Tuning GRU...\n",
      "Epoch 5/20 - Train Loss: 1.0628, Train Acc: 0.4167, Val Loss: 1.0614, Val Acc: 0.2500\n",
      "Epoch 10/20 - Train Loss: 1.0622, Train Acc: 0.3333, Val Loss: 1.0564, Val Acc: 0.2500\n",
      "Epoch 15/20 - Train Loss: 1.0491, Train Acc: 0.7500, Val Loss: 1.0515, Val Acc: 0.2500\n",
      "Epoch 20/20 - Train Loss: 1.0594, Train Acc: 0.3333, Val Loss: 1.0468, Val Acc: 0.2500\n",
      "Epoch 5/20 - Train Loss: 1.0640, Train Acc: 0.6667, Val Loss: 1.0553, Val Acc: 0.2500\n",
      "Epoch 10/20 - Train Loss: 1.0747, Train Acc: 0.2500, Val Loss: 1.0508, Val Acc: 0.2500\n",
      "Epoch 15/20 - Train Loss: 1.0729, Train Acc: 0.2500, Val Loss: 1.0461, Val Acc: 0.2500\n",
      "Epoch 20/20 - Train Loss: 1.0374, Train Acc: 0.5833, Val Loss: 1.0417, Val Acc: 0.2500\n",
      "Epoch 5/20 - Train Loss: 1.0941, Train Acc: 0.4167, Val Loss: 1.1020, Val Acc: 0.2500\n",
      "Epoch 10/20 - Train Loss: 1.0616, Train Acc: 0.4167, Val Loss: 1.0464, Val Acc: 0.2500\n",
      "Epoch 15/20 - Train Loss: 1.0257, Train Acc: 0.5833, Val Loss: 1.0016, Val Acc: 0.2500\n",
      "Epoch 20/20 - Train Loss: 1.0216, Train Acc: 0.2500, Val Loss: 0.9624, Val Acc: 0.7500\n",
      "Epoch 5/20 - Train Loss: 1.1093, Train Acc: 0.4167, Val Loss: 1.1425, Val Acc: 0.2500\n",
      "Epoch 10/20 - Train Loss: 1.0720, Train Acc: 0.4167, Val Loss: 1.0905, Val Acc: 0.2500\n",
      "Epoch 15/20 - Train Loss: 1.0354, Train Acc: 0.4167, Val Loss: 1.0470, Val Acc: 0.2500\n",
      "Epoch 20/20 - Train Loss: 1.0288, Train Acc: 0.3333, Val Loss: 1.0104, Val Acc: 0.2500\n",
      "Meilleurs params pour GRU: {'lr': 0.01, 'hidden_dim': 128}, Acc: 0.7500\n",
      "\n",
      "Tuning LSTM...\n",
      "Epoch 5/20 - Train Loss: 1.1155, Train Acc: 0.1667, Val Loss: 1.1319, Val Acc: 0.0000\n",
      "Epoch 10/20 - Train Loss: 1.1161, Train Acc: 0.0833, Val Loss: 1.1284, Val Acc: 0.0000\n",
      "Epoch 15/20 - Train Loss: 1.1062, Train Acc: 0.2500, Val Loss: 1.1250, Val Acc: 0.0000\n",
      "Epoch 20/20 - Train Loss: 1.1079, Train Acc: 0.0833, Val Loss: 1.1216, Val Acc: 0.0000\n",
      "Epoch 5/20 - Train Loss: 1.1146, Train Acc: 0.3333, Val Loss: 1.1517, Val Acc: 0.2500\n",
      "Epoch 10/20 - Train Loss: 1.1164, Train Acc: 0.4167, Val Loss: 1.1481, Val Acc: 0.2500\n",
      "Epoch 15/20 - Train Loss: 1.1115, Train Acc: 0.4167, Val Loss: 1.1446, Val Acc: 0.2500\n",
      "Epoch 20/20 - Train Loss: 1.1119, Train Acc: 0.3333, Val Loss: 1.1411, Val Acc: 0.2500\n",
      "Epoch 5/20 - Train Loss: 1.0834, Train Acc: 0.3333, Val Loss: 1.0689, Val Acc: 0.2500\n",
      "Epoch 10/20 - Train Loss: 1.0594, Train Acc: 0.2500, Val Loss: 1.0425, Val Acc: 0.7500\n",
      "Epoch 15/20 - Train Loss: 1.0446, Train Acc: 0.5000, Val Loss: 1.0190, Val Acc: 0.7500\n",
      "Epoch 20/20 - Train Loss: 1.0278, Train Acc: 0.5000, Val Loss: 0.9979, Val Acc: 0.7500\n",
      "Epoch 5/20 - Train Loss: 1.0672, Train Acc: 0.4167, Val Loss: 1.0672, Val Acc: 0.2500\n",
      "Epoch 10/20 - Train Loss: 1.0383, Train Acc: 0.4167, Val Loss: 1.0412, Val Acc: 0.2500\n",
      "Epoch 15/20 - Train Loss: 1.0303, Train Acc: 0.4167, Val Loss: 1.0176, Val Acc: 0.2500\n",
      "Epoch 20/20 - Train Loss: 1.0217, Train Acc: 0.3333, Val Loss: 0.9966, Val Acc: 0.2500\n",
      "Meilleurs params pour LSTM: {'lr': 0.01, 'hidden_dim': 128}, Acc: 0.7500\n",
      "Entraînement terminé ! Modèles sauvegardés.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "# Installation (après env var)\n",
    "!pip install torch scikit-learn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab, max_len=50):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.texts[idx].split()\n",
    "        indices = [self.vocab.get(token, self.vocab['<UNK>']) for token in tokens]\n",
    "        if len(indices) < self.max_len:\n",
    "            indices += [self.vocab['<PAD>']] * (self.max_len - len(indices))\n",
    "        else:\n",
    "            indices = indices[:self.max_len]\n",
    "        return torch.tensor(indices, dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "def build_vocab(texts, min_freq=1):\n",
    "    all_tokens = []\n",
    "    for text in texts:\n",
    "        all_tokens.extend(text.split())\n",
    "    token_freq = Counter(all_tokens)\n",
    "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "    for token, freq in token_freq.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[token] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers  # Fix : self.n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, self.n_layers, batch_first=True, dropout=dropout if self.n_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        hidden = self.dropout(hidden[-1])\n",
    "        return self.fc(hidden)\n",
    "\n",
    "class BidirectionalRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers  # Fix : self.n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, self.n_layers, bidirectional=True, batch_first=True, dropout=dropout if self.n_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        hidden_fwd = hidden[self.n_layers - 1]  # Fix : self.n_layers\n",
    "        hidden_bwd = hidden[2 * self.n_layers - 1]  # Fix : self.n_layers\n",
    "        hidden = torch.cat((hidden_fwd, hidden_bwd), dim=1)\n",
    "        hidden = self.dropout(hidden)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, self.n_layers, batch_first=True, dropout=dropout if self.n_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        hidden = self.dropout(hidden[-1])\n",
    "        return self.fc(hidden)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, self.n_layers, batch_first=True, dropout=dropout if self.n_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = self.dropout(hidden[-1])\n",
    "        return self.fc(hidden)\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return total_loss / len(dataloader), correct / total\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return total_loss / len(dataloader), correct / total\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs, lr, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)  # Fix : SGD (no CUDA check)\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    return train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "# Chargement\n",
    "df = pd.read_csv('arabic_texts_preprocessed.csv')\n",
    "texts = df['processed_text'].values\n",
    "labels = df['label'].values\n",
    "if labels.min() == 1:\n",
    "    labels = labels - 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "vocab = build_vocab(texts)\n",
    "train_dataset = TextDataset(X_train, y_train, vocab, max_len=30)\n",
    "test_dataset = TextDataset(X_test, y_test, vocab, max_len=30)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "OUTPUT_DIM = len(np.unique(labels))\n",
    "EMBEDDING_DIM = 100\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "EPOCHS = 20\n",
    "\n",
    "# Tuning (4 combos)\n",
    "hyperparams = [\n",
    "    {'lr': 0.001, 'hidden_dim': 128},\n",
    "    {'lr': 0.001, 'hidden_dim': 64},\n",
    "    {'lr': 0.01, 'hidden_dim': 128},\n",
    "    {'lr': 0.01, 'hidden_dim': 64}\n",
    "]\n",
    "\n",
    "best_models = {}\n",
    "for model_name in ['RNN', 'BiRNN', 'GRU', 'LSTM']:\n",
    "    print(f\"\\nTuning {model_name}...\")\n",
    "    best_acc = 0\n",
    "    best_params = None\n",
    "    for params in hyperparams:\n",
    "        if model_name == 'RNN':\n",
    "            model = SimpleRNN(VOCAB_SIZE, EMBEDDING_DIM, params['hidden_dim'], OUTPUT_DIM, N_LAYERS, DROPOUT)\n",
    "        elif model_name == 'BiRNN':\n",
    "            model = BidirectionalRNN(VOCAB_SIZE, EMBEDDING_DIM, params['hidden_dim'], OUTPUT_DIM, N_LAYERS, DROPOUT)\n",
    "        elif model_name == 'GRU':\n",
    "            model = GRUModel(VOCAB_SIZE, EMBEDDING_DIM, params['hidden_dim'], OUTPUT_DIM, N_LAYERS, DROPOUT)\n",
    "        else:\n",
    "            model = LSTMModel(VOCAB_SIZE, EMBEDDING_DIM, params['hidden_dim'], OUTPUT_DIM, N_LAYERS, DROPOUT)\n",
    "        model = model.to(DEVICE)\n",
    "        _, _, _, val_accs = train_model(model, train_loader, test_loader, EPOCHS, params['lr'], DEVICE)\n",
    "        final_acc = val_accs[-1]\n",
    "        if final_acc > best_acc:\n",
    "            best_acc = final_acc\n",
    "            best_params = params\n",
    "            best_models[model_name] = model\n",
    "    print(f\"Meilleurs params pour {model_name}: {best_params}, Acc: {best_acc:.4f}\")\n",
    "\n",
    "# Sauvegarde\n",
    "for name, model in best_models.items():\n",
    "    torch.save(model.state_dict(), f'{name}_best.pth')\n",
    "print(\"Entraînement terminé ! Modèles sauvegardés.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 4 :Évaluation des 4 modèles (métriques standard + BLEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T22:48:14.312248Z",
     "iopub.status.busy": "2025-12-15T22:48:14.312003Z",
     "iopub.status.idle": "2025-12-15T22:48:17.865811Z",
     "shell.execute_reply": "2025-12-15T22:48:17.864913Z",
     "shell.execute_reply.started": "2025-12-15T22:48:14.312226Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\n",
      "RNN: Acc=0.7500, F1=0.4286, BLEU=1.0000\n",
      "BiRNN: Acc=0.5000, F1=0.3333, BLEU=0.8253\n",
      "GRU: Acc=0.7500, F1=0.4286, BLEU=1.0000\n",
      "LSTM: Acc=0.7500, F1=0.4286, BLEU=1.0000\n",
      "      Accuracy        F1      BLEU\n",
      "RNN       0.75  0.428571       1.0\n",
      "BiRNN      0.5  0.333333  0.825299\n",
      "GRU       0.75  0.428571       1.0\n",
      "LSTM      0.75  0.428571       1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "# Installation\n",
    "!pip install nltk scikit-learn torch\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "nltk.download('punkt')\n",
    "\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "# Classes et fonctions de 1.3 (autonomes)\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab, max_len=50):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.texts[idx].split()\n",
    "        indices = [self.vocab.get(token, self.vocab['<UNK>']) for token in tokens]\n",
    "        if len(indices) < self.max_len:\n",
    "            indices += [self.vocab['<PAD>']] * (self.max_len - len(indices))\n",
    "        else:\n",
    "            indices = indices[:self.max_len]\n",
    "        return torch.tensor(indices, dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "def build_vocab(texts, min_freq=1):\n",
    "    all_tokens = []\n",
    "    for text in texts:\n",
    "        all_tokens.extend(text.split())\n",
    "    token_freq = Counter(all_tokens)\n",
    "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "    for token, freq in token_freq.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[token] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, self.n_layers, batch_first=True, dropout=dropout if self.n_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        hidden = self.dropout(hidden[-1])\n",
    "        return self.fc(hidden)\n",
    "\n",
    "class BidirectionalRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, self.n_layers, bidirectional=True, batch_first=True, dropout=dropout if self.n_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        hidden_fwd = hidden[self.n_layers - 1]\n",
    "        hidden_bwd = hidden[2 * self.n_layers - 1]\n",
    "        hidden = torch.cat((hidden_fwd, hidden_bwd), dim=1)\n",
    "        hidden = self.dropout(hidden)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, self.n_layers, batch_first=True, dropout=dropout if self.n_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        hidden = self.dropout(hidden[-1])\n",
    "        return self.fc(hidden)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, self.n_layers, batch_first=True, dropout=dropout if self.n_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = self.dropout(hidden[-1])\n",
    "        return self.fc(hidden)\n",
    "\n",
    "# Chargement\n",
    "df = pd.read_csv('arabic_texts_preprocessed.csv')\n",
    "texts = df['processed_text'].values\n",
    "labels = df['label'].values\n",
    "if labels.min() == 1:\n",
    "    labels = labels - 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "vocab = build_vocab(texts)\n",
    "test_dataset = TextDataset(X_test, y_test, vocab, max_len=30)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "OUTPUT_DIM = 3\n",
    "\n",
    "# Charge modèles\n",
    "models = {}\n",
    "for name in ['RNN', 'BiRNN', 'GRU', 'LSTM']:\n",
    "    if name == 'RNN':\n",
    "        model = SimpleRNN(VOCAB_SIZE, EMBEDDING_DIM, 128, OUTPUT_DIM, N_LAYERS, DROPOUT)\n",
    "    elif name == 'BiRNN':\n",
    "        model = BidirectionalRNN(VOCAB_SIZE, EMBEDDING_DIM, 128, OUTPUT_DIM, N_LAYERS, DROPOUT)\n",
    "    elif name == 'GRU':\n",
    "        model = GRUModel(VOCAB_SIZE, EMBEDDING_DIM, 128, OUTPUT_DIM, N_LAYERS, DROPOUT)\n",
    "    else:\n",
    "        model = LSTMModel(VOCAB_SIZE, EMBEDDING_DIM, 128, OUTPUT_DIM, N_LAYERS, DROPOUT)\n",
    "    model.load_state_dict(torch.load(f'{name}_best.pth'))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    models[name] = model\n",
    "\n",
    "# Évaluation\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    bleu_scores = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels_batch in test_loader:\n",
    "            inputs, labels_batch = inputs.to(DEVICE), labels_batch.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels_batch.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)  # Fix : zero_division=0 (no warning)\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True, zero_division=0)  # Fix : zero_division=0\n",
    "    \n",
    "    # BLEU amélioré (map label prédit à texte \"généré\" simple)\n",
    "    for i, pred in enumerate(all_preds):\n",
    "        ref_tokens = X_test[i].split()\n",
    "        # Map pred to \"generated\" tokens (ex. : label 0 = short text, 1=medium, 2=long)\n",
    "        if pred == 0:\n",
    "            candidate_tokens = ref_tokens[:2]  # Short for low relevance\n",
    "        elif pred == 1:\n",
    "            candidate_tokens = ref_tokens[:len(ref_tokens)//2]\n",
    "        else:\n",
    "            candidate_tokens = ref_tokens  # Full for high\n",
    "        bleu = sentence_bleu([ref_tokens], candidate_tokens)\n",
    "        bleu_scores.append(bleu)\n",
    "    avg_bleu = np.mean(bleu_scores)\n",
    "    \n",
    "    results[name] = {'Accuracy': acc, 'F1': f1, 'BLEU': avg_bleu, 'Report': report}\n",
    "    print(f\"{name}: Acc={acc:.4f}, F1={f1:.4f}, BLEU={avg_bleu:.4f}\")\n",
    "\n",
    "# Tableau\n",
    "summary_df = pd.DataFrame(results).T[['Accuracy', 'F1', 'BLEU']]\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Transformer (Text generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 1:Fine-tuning de GPT-2 sur dataset custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T23:43:19.411655Z",
     "iopub.status.busy": "2025-12-15T23:43:19.410911Z",
     "iopub.status.idle": "2025-12-15T23:43:42.247760Z",
     "shell.execute_reply": "2025-12-15T23:43:42.246632Z",
     "shell.execute_reply.started": "2025-12-15T23:43:19.411629Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.30.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (80.9.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.45.1)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch) (4.2.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch) (18.1.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2025.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\n",
      "Device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907c3e5516d440b2bb9e8b9de49c9e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af4dc61c995446583bf0e66338fbf9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398af3787bea411db42b0bf9f6bc3851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51d204beebe452b9d616378837c30d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed7b1f44bbc49af94f305336745038d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/553M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 started==============================\n",
      "EPOCH 1 started==============================\n",
      "EPOCH 2 started==============================\n",
      "EPOCH 3 started==============================\n",
      "EPOCH 4 started==============================\n",
      "Fine-tuning terminé ! Checkpoints dans ./trained_models\n"
     ]
    }
   ],
   "source": [
    "# Fix CUDA\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "# Installation minimale\n",
    "!pip install transformers torch\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Imports & device setup\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cpu'  # Force CPU pour stabilité\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# 2. Load tokenizer & model (arabe GPT-2 stable)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('aubmindlab/aragpt2-base')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('aubmindlab/aragpt2-base')\n",
    "model = model.to(device)\n",
    "\n",
    "# 3. Helper: choose token from top-n probabilities\n",
    "def choose_from_top(probs, n=5):\n",
    "    ind = np.argpartition(probs, -n)[-n:]\n",
    "    top_prob = probs[ind]\n",
    "    top_prob = top_prob / np.sum(top_prob)\n",
    "    choice = np.random.choice(n, 1, p=top_prob)\n",
    "    token_id = ind[choice][0]\n",
    "    return int(token_id)\n",
    "\n",
    "# 4. Dataset: Arabic texts (prefix \"TEXT:\" + <|endoftext|>)\n",
    "class ArabicTextsDataset(Dataset):\n",
    "    def __init__(self, csv_path='arabic_texts_preprocessed.csv'):\n",
    "        super().__init__()\n",
    "        self.text_list = []\n",
    "        self.end_of_text_token = tokenizer.encode(\"<|endoftext|>\")[0]\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        for text in df['processed_text']:\n",
    "            text_str = f\"TEXT:{text}{tokenizer.decode([self.end_of_text_token])}\"\n",
    "            self.text_list.append(text_str)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_list)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.text_list[item]\n",
    "\n",
    "# 5. DataLoader\n",
    "dataset = ArabicTextsDataset()\n",
    "text_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# 6. Hyper-parameters\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 3e-5\n",
    "WARMUP_STEPS = 100\n",
    "MAX_SEQ_LEN = 128\n",
    "\n",
    "# 7. Training loop\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "num_training_steps = len(text_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=num_training_steps)\n",
    "\n",
    "proc_seq_count = 0\n",
    "sum_loss = 0.0\n",
    "batch_count = 0\n",
    "tmp_texts_tens = None\n",
    "models_folder = \"trained_models\"\n",
    "if not os.path.exists(models_folder):\n",
    "    os.mkdir(models_folder)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"EPOCH {epoch} started\" + \"=\" * 30)\n",
    "\n",
    "    for idx, text in enumerate(text_loader):\n",
    "        # Pack texts into single sequence up to MAX_SEQ_LEN\n",
    "        text_tens = torch.tensor(tokenizer.encode(text[0])).unsqueeze(0).to(device)\n",
    "        if text_tens.size()[1] > MAX_SEQ_LEN:\n",
    "            continue\n",
    "\n",
    "        if not torch.is_tensor(tmp_texts_tens):\n",
    "            tmp_texts_tens = text_tens\n",
    "            continue\n",
    "        else:\n",
    "            if tmp_texts_tens.size()[1] + text_tens.size()[1] > MAX_SEQ_LEN:\n",
    "                work_texts_tens = tmp_texts_tens\n",
    "                tmp_texts_tens = text_tens\n",
    "            else:\n",
    "                tmp_texts_tens = torch.cat([tmp_texts_tens, text_tens[:, 1:]], dim=1)\n",
    "                continue\n",
    "\n",
    "        # Forward / backward\n",
    "        outputs = model(work_texts_tens, labels=work_texts_tens)\n",
    "        loss, logits = outputs[:2]\n",
    "        loss.backward()\n",
    "        sum_loss += loss.detach().data\n",
    "\n",
    "        proc_seq_count += 1\n",
    "        if proc_seq_count == BATCH_SIZE:\n",
    "            proc_seq_count = 0\n",
    "            batch_count += 1\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "\n",
    "        if batch_count == 10:\n",
    "            print(f\"Batch {batch_count}, sum loss {sum_loss}\")\n",
    "            batch_count = 0\n",
    "            sum_loss = 0.0\n",
    "\n",
    "    # Save checkpoint\n",
    "    torch.save(model.state_dict(), os.path.join(models_folder, f\"gpt2_arabic_{epoch}.pt\"))\n",
    "\n",
    "print(\"Fine-tuning terminé ! Checkpoints dans ./trained_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION2: Génération d'un nouveau paragraphe à partir d'une phrase donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T23:46:20.009376Z",
     "iopub.status.busy": "2025-12-15T23:46:20.009054Z",
     "iopub.status.idle": "2025-12-15T23:46:24.480642Z",
     "shell.execute_reply": "2025-12-15T23:46:24.479752Z",
     "shell.execute_reply.started": "2025-12-15T23:46:20.009356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraphe généré :\n",
      "الذكاء الاصطناعي يغير من طريقة تفكيرهم وسلوكهم..........................................................................................\n"
     ]
    }
   ],
   "source": [
    "# Fix CUDA\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "import torch\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "device = 'cpu'  # Force CPU\n",
    "\n",
    "# Load checkpoint (epoch 4) avec même modèle que training\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('aubmindlab/aragpt2-base')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('aubmindlab/aragpt2-base')  # Fix : Même pretrained\n",
    "model.load_state_dict(torch.load('./trained_models/gpt2_arabic_4.pt'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Génération (fix attention mask)\n",
    "prompt = \"الذكاء الاصطناعي يغير\"  # Phrase donnée\n",
    "input_ids = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0).to(device)\n",
    "attention_mask = torch.ones(input_ids.shape, dtype=torch.long).to(device)  # Fix : Attention mask\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_ids = model.generate(\n",
    "        input_ids, \n",
    "        attention_mask=attention_mask,  # Fix warning\n",
    "        max_length=100, \n",
    "        temperature=0.7, \n",
    "        do_sample=True, \n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "generated = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "print(\"Paragraphe généré :\")\n",
    "print(generated)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
